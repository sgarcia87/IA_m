import heapq
import openai
import networkx as nx
import json
import re
import wikipediaapi
import numpy as np
from pyvis.network import Network
from sentence_transformers import SentenceTransformer, util
import os
from nltk.corpus import wordnet as wn
from difflib import get_close_matches
import nltk
import time
import matplotlib.pyplot as plt
from collections import Counter
import signal

# Evita los mensajes de descarga de NLTK
nltk.data.path.append(os.path.expanduser('~/nltk_data'))
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

# üîπ Cargar API Key desde variable de entorno
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# üîπ Manejar interrupci√≥n con Ctrl+C para evitar cierres forzados
signal.signal(signal.SIGINT, lambda sig, frame: exec('raise KeyboardInterrupt'))

if OPENAI_API_KEY is None:
    raise ValueError("‚ùå ERROR: La variable de entorno 'OPENAI_API_KEY' no est√° configurada.")

# üîπ Crear cliente de OpenAI con la nueva API
client = openai.OpenAI(api_key=OPENAI_API_KEY)


# üîπ Cargar modelo de embeddings
modelo = SentenceTransformer('all-MiniLM-L6-v2')
modelo_embeddings = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")


# üîπ Base de dualidades predefinidas
dualidades_base = {
    "fr√≠o": "calor", "oscuridad": "luz", "muerte": "vida",
    "izquierda": "derecha", "negativo":  "positivo", "contracci√≥n": "expansi√≥n",
    "femenino": "masculino", "malo": "bueno", "caos": "orden",
    "mentira": "verdad", "tristeza": "alegr√≠a", "odio": "amor"
}

# üîπ Nodo central
NODO_CENTRAL = "consciencia"

expansion_activa = True  # Variable global para controlar la expansi√≥n

# üîπ Base de conceptos iniciales para evitar que la red inicie vac√≠a
SEMILLA_INICIAL = ["matem√°ticas", "geometr√≠a", "f√≠sica", "consciencia", "universo"]

import json
import networkx as nx

# Cargar el grafo desde el archivo JSON
grafo_json = "grafo_consciencia.json"

def cargar_grafo():
    G = nx.DiGraph()
    try:
        with open(grafo_json, "r") as f:
            datos = json.load(f)
            for nodo in datos["nodos"]:
                G.add_node(nodo)
            for u, v in datos["edges"]:
                G.add_edge(u, v)
            print(f"Grafo cargado con {len(G.nodes())} nodos y {len(G.edges())} conexiones.")
    except FileNotFoundError:
        print("‚ö†Ô∏è No se encontr√≥ ning√∫n grafo para adjuntar.")
    return G

def cargar_diccionario():
    try:
        with open("diccionario.json", "r", encoding="utf-8") as f:
            diccionario = json.load(f)
            if not diccionario:  # Si est√° vac√≠o, agregar semilla inicial
                print("‚ö†Ô∏è Diccionario vac√≠o. Agregando conceptos iniciales...")
                for concepto in SEMILLA_INICIAL:
                    diccionario[concepto] = []  # Iniciar con una lista vac√≠a de conexiones
                guardar_diccionario(diccionario)
            return diccionario
    except FileNotFoundError:
        print("‚ö†Ô∏è Diccionario no encontrado, creando uno nuevo con semilla inicial.")
        diccionario = {concepto: [] for concepto in SEMILLA_INICIAL}
        guardar_diccionario(diccionario)
        return diccionario

# üîπ Guardar la red fractal
def guardar_red(G):
    with open("red_fractal.json", "w") as f:
        json.dump(nx.node_link_data(G, edges="links"), f)
        
ARCHIVO_HISTORIAL = "historial_expansion.json"
def cargar_historial():
    """ Carga el historial de expansiones previas """
    try:
        with open(ARCHIVO_HISTORIAL, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def guardar_historial(historial):
    """ Guarda el historial de expansiones """
    with open(ARCHIVO_HISTORIAL, "w", encoding="utf-8") as f:
        json.dump(historial, f, ensure_ascii=False, indent=4)

# Archivo donde se guardar√° la lista de espera
ARCHIVO_ESPERA_NODOS = "espera_nodos.json"

# Cargar nodos en espera desde un archivo JSON
def cargar_espera_nodos():
    try:
        with open(ARCHIVO_ESPERA_NODOS, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

# Guardar nodos en espera en un archivo JSON
def guardar_espera_nodos(espera_nodos):
    with open(ARCHIVO_ESPERA_NODOS, "w", encoding="utf-8") as f:
        json.dump(espera_nodos, f, ensure_ascii=False, indent=4)

ARCHIVO_REGISTRO = "registro_expansion.json"

def cargar_registro():
    """ Carga el registro de expansi√≥n """
    try:
        with open(ARCHIVO_REGISTRO, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print("‚ö†Ô∏è Archivo de registro no encontrado, creando uno nuevo.")
        guardar_registro([])  # Guardar una lista vac√≠a para inicializarlo
        return []

def guardar_registro(registro):
    """ Guarda el registro de expansi√≥n """
    with open(ARCHIVO_REGISTRO, "w", encoding="utf-8") as f:
        json.dump(registro, f, ensure_ascii=False, indent=4)

def visualizar_crecimiento_red():
    """ Grafica la evoluci√≥n del n√∫mero de nodos en la red fractal """
    registro = cargar_registro()
    if not registro:
        print("‚ö†Ô∏è No hay datos en el registro de expansi√≥n.")
        return

    tiempos = [entry["timestamp"] for entry in registro]
    tiempos.sort()
    tiempos = np.array(tiempos) - tiempos[0]  
    nodos_totales = list(range(1, len(tiempos) + 1))  

    plt.figure(figsize=(10, 5))
    plt.plot(tiempos, nodos_totales, marker="o", linestyle="-", color="blue")
    plt.xlabel("Tiempo (segundos desde el inicio)")
    plt.ylabel("N√∫mero de nodos en la red")
    plt.title("Evoluci√≥n del Crecimiento de la Red Fractal")
    plt.grid()
    plt.savefig("crecimiento_red.png")
    print("üìä Gr√°fico guardado como 'crecimiento_red.png'.")

def visualizar_metodos_expansion():
    """ Grafica la cantidad de expansiones por m√©todo (Wikipedia, GPT-4, Embeddings) """
    registro = cargar_registro()
    if not registro:
        print("‚ö†Ô∏è No hay datos en el registro de expansi√≥n.")
        return

    # Contar m√©todos de expansi√≥n
    metodos = {"Wikipedia": 0, "GPT-4": 0, "Embeddings": 0}
    for entry in registro:
        metodo = entry["metodo"]
        if metodo in metodos:
            metodos[metodo] += 1

    # Graficar
    plt.figure(figsize=(7, 7))
    plt.pie(metodos.values(), labels=metodos.keys(), autopct="%1.1f%%", startangle=90, colors=["green", "red", "blue"])
    plt.title("Distribuci√≥n de M√©todos de Expansi√≥n en la Red")
    plt.show()


def visualizar_distribucion_conexiones(G):
    """ Grafica la distribuci√≥n de conexiones en la red """
    grados = [G.degree(nodo) for nodo in G.nodes()]

    plt.figure(figsize=(8, 5))
    plt.hist(grados, bins=range(1, max(grados) + 1), color="purple", alpha=0.7, edgecolor="black")
    plt.xlabel("N√∫mero de conexiones por nodo")
    plt.ylabel("Cantidad de nodos")
    plt.title("Distribuci√≥n de Conexiones en la Red Fractal")
    plt.grid()
    plt.show()

# Cargar nodos en espera al inicio del programa
espera_nodos = cargar_espera_nodos()

# üîπ Normalizar t√©rminos
def normalizar_termino(termino):
    termino = re.sub(r"[^a-zA-Z0-9√°√©√≠√≥√∫√º√± ]", "_", termino)  # Mantiene espacios
    return termino.lower().strip().replace(" ", "_")


# üîπ Nueva funci√≥n para consultar ChatGPT
def consultar_chatgpt(tema, diccionario):
    tema = corregir_termino(tema, diccionario).lower()  # üîπ Corregir y forzar a min√∫sculas

    try:
        print(f"ü§ñ Consultando ChatGPT sobre: {tema}...")

        respuesta = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": (
#                    "Eres un experto en matem√°ticas, geometr√≠a, estructuras fractales, biolog√≠a, f√≠sica y todas las ciencias. "
#                    "Tu objetivo es generar t√©rminos t√©cnicos. "
                        "Proporciona solo una lista de t√©rminos separados por comas definiendo el concepto propuesto. TUS RESULTADOS TIENEN QUE SER ENTENDIBLES PARA UN PRIMARIA NI√ëO DE PRIMARIA."
                        "Responde exclusivamente con una lista separada por comas, sin explicaciones, sin n√∫meros (al menos para contarlos, pero s√≠ si forma parte del concepto) sin frases ni puntos porfavor..."
                )},
                {"role": "user", "content": f"Dame solo t√©rminos t√©cnicos relacionados con {tema}."}
            ]
        )

        # Verifica que la respuesta no est√© vac√≠a
        if not respuesta.choices:
            print("‚ö†Ô∏è ChatGPT no devolvi√≥ resultados.")
            return []

        # Obtener la respuesta como texto
        texto_respuesta = respuesta.choices[0].message.content.strip().lower()  # üîπ Convertir a min√∫sculas
        
        # Limpiar la respuesta eliminando caracteres no deseados
        conceptos = re.split(r',\s*', texto_respuesta)
        conceptos = [c.strip() for c in conceptos if c and es_nodo_relevante(c)]


        print("üìù ChatGPT sugiere los siguientes conceptos:")
        for concepto in conceptos:
            print(f"- {concepto}")

        return conceptos

    except Exception as e:
        print(f"‚ùå Error consultando ChatGPT: {e}")
        return []

def calcular_prioridad_nodo(G, nodo):
    """ Calcula la prioridad de un nodo bas√°ndose en su importancia en la red """
    conexiones = G.degree(nodo)
    centralidad = nx.degree_centrality(G).get(nodo, 0)  # Centralidad del nodo
    peso_promedio = sum([G.edges[nodo, neighbor].get('weight', 1) for neighbor in G.neighbors(nodo)]) / (conexiones or 1)

    # Prioridad basada en conexiones, peso de enlaces y centralidad
    prioridad = (conexiones * 0.4) + (centralidad * 0.4) + (peso_promedio * 0.2)
    return prioridad
    
def priorizar_expansion(G):
    """ Retorna una cola de nodos a expandir, ordenados por prioridad """
    prioridad_nodos = []
    
    for nodo in G.nodes():
        if G.degree(nodo) < 6:  # Solo prioriza nodos con pocas conexiones
            prioridad = calcular_prioridad_nodo(G, nodo)
            heapq.heappush(prioridad_nodos, (-prioridad, nodo))  # Heap inverso para prioridad alta

    return [heapq.heappop(prioridad_nodos)[1] for _ in range(len(prioridad_nodos))]
    
def generar_reportes():
    """ Genera visualizaciones cada cierto tiempo """
    print("üìä Generando reportes visuales de la red fractal...")
    visualizar_crecimiento_red()  # <-- REINTEGRADA AQU√ç
    visualizar_metodos_expansion()
    visualizar_distribucion_conexiones(G)

def registrar_expansion(nodo, nuevos_conceptos, metodo):
    """ Registra cada expansi√≥n realizada """
    registro = cargar_registro()
    nueva_entrada = {
        "nodo": nodo,
        "nuevos_conceptos": nuevos_conceptos,
        "metodo": metodo,
        "timestamp": time.time()
    }
    registro.append(nueva_entrada)
    guardar_registro(registro)

def ver_registro():
    """ Muestra el historial de expansiones """
    registro = cargar_registro()
    
    print("\nüìú Historial de Expansi√≥n:")
    for entrada in registro[-10:]:  # Solo mostrar las 10 √∫ltimas expansiones
        print(f"üîπ {entrada['nodo']} ‚Üí {entrada['nuevos_conceptos']} (via {entrada['metodo']})")

# üîπ Agregar llamadas en puntos clave
def expansion_prioritaria(G, diccionario):
    """ Expande los nodos m√°s prioritarios en la red """
    nodos_a_expandir = priorizar_expansion(G)[:10]  
    for nodo in nodos_a_expandir:
        print(f"üîç Expansi√≥n prioritaria en: {nodo}")
        nuevos_conceptos = consultar_chatgpt(nodo, diccionario)
        if nuevos_conceptos:
            G = agregar_nuevo_nodo(G, diccionario, nuevos_conceptos)
            registrar_expansion(nodo, nuevos_conceptos, "GPT-4")  # üîπ Se registra aqu√≠
        expandir_concepto_embedding(nodo, G, diccionario)
        registrar_expansion(nodo, [], "Embeddings")  # üîπ Se registra la expansi√≥n con embeddings
    guardar_red(G)

def cargar_red():
    diccionario = cargar_diccionario()
    try:
        with open("red_fractal.json", "r") as f:
            data = json.load(f)
            G = nx.node_link_graph(data, edges="links")

            # üîπ Corregir nombres de nodos: convertir "_" en espacios
            G = nx.relabel_nodes(G, {nodo: nodo.replace("_", " ") for nodo in G.nodes()})
            
            print("‚úÖ Red fractal cargada correctamente.")
            return G, diccionario
    except FileNotFoundError:
        print("üöÄ Creando nueva red fractal con semilla inicial.")

        if not diccionario:
            diccionario = {concepto.replace("_", " "): [] for concepto in SEMILLA_INICIAL}
            guardar_diccionario(diccionario)

        G = nx.DiGraph()
        G.add_node(NODO_CENTRAL.replace("_", " "))  # Agregar nodo central corregido

        # üîπ Conectar dualidades predefinidas con nombres corregidos
        for concepto, dual in dualidades_base.items():
            concepto = concepto.replace("_", " ")
            dual = dual.replace("_", " ")
            G.add_node(concepto)
            G.add_node(dual)
            G.add_edge(concepto, dual, weight=2.0)
            G.add_edge(dual, concepto, weight=2.0)
            G.add_edge(concepto, NODO_CENTRAL, weight=1.5)
        # üîπ Conectar los conceptos de la semilla entre s√≠
        for i in range(len(SEMILLA_INICIAL)):
            for j in range(i + 1, len(SEMILLA_INICIAL)):
                concepto1 = SEMILLA_INICIAL[i].replace("_", " ")
                concepto2 = SEMILLA_INICIAL[j].replace("_", " ")
                G.add_edge(concepto1, concepto2, weight=1.2)
        guardar_red(G)
        return G, diccionario

# üîπ Consultar Wikipedia y detectar t√©rminos opuestos
def consultar_wikipedia(concepto, G, diccionario):
    concepto = corregir_termino(concepto, diccionario)  # Correcci√≥n antes de la consulta
    consulta = normalizar_termino(concepto)
    print(f"üåç Consultando Wikipedia para: {consulta}...")
    wiki = wikipediaapi.Wikipedia(language='es', user_agent="IAConsciente/1.0")
    page = wiki.page(consulta)
    if not page.exists():
        print(f"‚ùå Wikipedia: No se encontr√≥ informaci√≥n sobre {consulta}.")
        return "‚ùå No se encontr√≥ informaci√≥n en Wikipedia."
    resumen = page.summary[:500]
    print(f"üìñ Wikipedia: {consulta} encontrada.")
    print(f"üìú Resumen: {resumen}...")
    # Extraer solo los primeros 10 enlaces relevantes
    enlaces_relacionados = [link.strip() for link in list(page.links)[:10] if es_nodo_relevante(link)]
    # Mostrar los enlaces encontrados
    if enlaces_relacionados:
        print("üîó Wikipedia sugiere los siguientes conceptos:")
        for termino in enlaces_relacionados:
            print(f"- {termino}")
    for termino in enlaces_relacionados:
        if not es_nodo_relevante(termino):
            continue  # Filtra nodos irrelevantes
        # üîπ Mantener la capitalizaci√≥n de los t√©rminos
        termino = termino.strip()
        if termino not in G.nodes():
            G.add_node(termino)
            diccionario.setdefault(concepto, []).append(termino)
            G.add_edge(concepto, termino, weight=1.2)
        # ‚úÖ Se pasa el concepto original como 'concepto_base'
        dualidad_opuesta = detectar_dualidad(termino, G, concepto)
        if dualidad_opuesta and dualidad_opuesta in G.nodes():
            conectar_dualidad_con_equilibrio(termino, dualidad_opuesta, G)
    guardar_red(G)
    return f"üìñ Wikipedia: {resumen}...\nüîó M√°s info: {page.fullurl}"
    
def conectar_dualidad_con_equilibrio(concepto, dualidad, G):
    """ Conecta dos nodos como dualidades y a√±ade un nodo intermedio de equilibrio. """
    if not G.has_edge(concepto, dualidad):
        G.add_edge(concepto, dualidad, weight=2.5)
        G.add_edge(dualidad, concepto, weight=2.5)
        print(f"üîó Conectando {concepto} ‚Üî {dualidad} como dualidad.")

    # üîπ Intentar detectar un nodo superior din√°mico
    posibles_superiores = detectar_nodo_superior(concepto, dualidad, G)
    
    if posibles_superiores:
        nodo_superior = posibles_superiores[0]  # Tomamos el nodo con mayor similitud

        if nodo_superior not in G.nodes():
            G.add_node(nodo_superior)
            print(f"üÜï A√±adiendo nodo superior din√°mico: {nodo_superior}")

        # Conectar la dualidad al nodo superior
        G.add_edge(nodo_superior, concepto, weight=1.5)
        G.add_edge(nodo_superior, dualidad, weight=1.5)
        print(f"üîó Vinculando {concepto} y {dualidad} a {nodo_superior}")

    # üîπ Buscar el punto de equilibrio para esta dualidad
    nodo_equilibrio = detectar_nodo_equilibrio(concepto, dualidad)

    if nodo_equilibrio:
        if nodo_equilibrio not in G.nodes():
            G.add_node(nodo_equilibrio)
            print(f"üÜï A√±adiendo nodo de equilibrio: {nodo_equilibrio}")

        # Conectar el equilibrio con ambos extremos
        G.add_edge(nodo_equilibrio, concepto, weight=1.8)
        G.add_edge(nodo_equilibrio, dualidad, weight=1.8)
        print(f"‚öñÔ∏è Estableciendo equilibrio entre {concepto} y {dualidad} en {nodo_equilibrio}")

def detectar_nodo_equilibrio(concepto, dualidad):
    """ Determina un nodo de equilibrio basado en reglas predefinidas y embeddings. """
    nodos_equilibrio = {
        ("suma", "resta"): "promedio",
        ("multiplicaci√≥n", "divisi√≥n"): "ra√≠z cuadrada",
        ("positivo", "negativo"): "cero",
        ("orden", "caos"): "autoorganizaci√≥n",
        ("luz", "oscuridad"): "penumbra",
        ("bien", "mal"): "√©tica"
    }

    # Revisar si la dualidad est√° en la lista predefinida
    for (a, b), equilibrio in nodos_equilibrio.items():
        if (concepto == a and dualidad == b) or (concepto == b and dualidad == a):
            return equilibrio

    # Si no est√° en la lista, intentamos encontrar una relaci√≥n sem√°ntica con embeddings
    return detectar_equilibrio_embeddings(concepto, dualidad)
    
def detectar_equilibrio_embeddings(concepto, dualidad):
    """ Usa embeddings para detectar un nodo de equilibrio no predefinido. """
    palabras_relacionadas = ["equilibrio", "media", "neutro", "balance", "punto medio"]
    
    embedding_concepto = modelo_embeddings.encode(concepto, convert_to_tensor=True)
    embedding_dualidad = modelo_embeddings.encode(dualidad, convert_to_tensor=True)
    embeddings_referencia = modelo_embeddings.encode(palabras_relacionadas, convert_to_tensor=True)

    # Calcular similitud con palabras de equilibrio
    similitudes_concepto = util.pytorch_cos_sim(embedding_concepto, embeddings_referencia)[0]
    similitudes_dualidad = util.pytorch_cos_sim(embedding_dualidad, embeddings_referencia)[0]

    # Promediar similitudes y seleccionar el t√©rmino con mayor relaci√≥n
    similitudes_totales = (similitudes_concepto + similitudes_dualidad) / 2
    indice_max = similitudes_totales.argmax().item()

    return palabras_relacionadas[indice_max]  # Devuelve el t√©rmino de equilibrio m√°s cercano

# üîπ Filtrar nodos irrelevantes
def es_nodo_relevante(nodo):
    irrelevantes = [
        "art", "architecture", "thesaurus", "archive", "research", "manual", "RAE", "desambiguaci√≥n", "control de autoridades", "biblioteca", "Wikidata", "Library", "University"
    ]
    return not any(term in nodo.lower() for term in irrelevantes)


# üîπ Funci√≥n para extraer la ra√≠z de un concepto
def obtener_raiz(termino):
    """ Extrae la ra√≠z de un t√©rmino eliminando sufijos comunes. """
    return re.sub(r"_(t√°ctil|auditiva|sensorial|visual|espacial|profunda|sinest√©sica|expectante|intermodal|intr√≠nseca)$", "", termino)


# üîπ Guardar diccionario en un archivo JSON
def guardar_diccionario(diccionario):
    with open("diccionario.json", "w", encoding="utf-8") as f:
        json.dump(diccionario, f, ensure_ascii=False, indent=4)
       
def expansion_con_embeddings(G, diccionario):
    """ Expande autom√°ticamente la red usando embeddings """
    nodos_a_expandir = [nodo for nodo in G.nodes() if G.degree(nodo) < 2]

    for nodo in nodos_a_expandir:
        print(f"üß† Expansi√≥n sem√°ntica para: {nodo}")
        expandir_concepto_embedding(nodo, G, diccionario)

    guardar_red(G)

MAX_EXPANSIONES = 10  # L√≠mite de expansiones por iteraci√≥n
UMBRAL_SIMILITUD = 0.75  # Solo agrega t√©rminos con alta similitud

def expansion_controlada(G, diccionario):
    """ Controla la expansi√≥n autom√°tica evitando t√©rminos irrelevantes """
    nodos_a_expandir = [nodo for nodo in G.nodes() if G.degree(nodo) < 2]
    
    for i, nodo in enumerate(nodos_a_expandir):
        if i >= MAX_EXPANSIONES:
            break  # Detener expansi√≥n si se alcanza el l√≠mite

        print(f"üõ† Expandiendo nodo controlado: {nodo}")

        conceptos = consultar_chatgpt(nodo, diccionario)
        conceptos_filtrados = [
            c for c in conceptos if max(
                util.pytorch_cos_sim(modelo.encode(c, convert_to_tensor=True), modelo.encode(nodo, convert_to_tensor=True))[0].tolist()
            ) > UMBRAL_SIMILITUD
        ]

        if conceptos_filtrados:
            G = agregar_nuevo_nodo(G, diccionario, conceptos_filtrados)

    guardar_red(G)

# üîπ Detectar dualidad con WordNet
def detectar_dualidad_wordnet(termino):
    antonimos = set()
    try:
        synsets = wn.synsets(termino, lang='spa')
        if not synsets:
            return []  # Retorna lista vac√≠a si no hay resultados

        for syn in synsets:
            for lemma in syn.lemmas('spa'):
                for ant in lemma.antonyms():
                    antonimos.add(ant.name())

    except Exception as e:
        print(f"‚ö†Ô∏è Error consultando WordNet para '{termino}': {e}")
    
    return list(antonimos)


# üîπ Corregir posibles errores en la entrada
def corregir_termino(termino, diccionario):
    if termino in diccionario:
        return termino  # Ya est√° bien escrito
    sugerencias = get_close_matches(termino, diccionario.keys(), n=1, cutoff=0.8)
    return sugerencias[0] if sugerencias else termino


# üîπ Detectar dualidad con embeddings
def detectar_dualidad_embeddings(nuevo_concepto, G, top_n=5):
    palabras_red = list(G.nodes())
    embedding_concepto = modelo.encode(nuevo_concepto, convert_to_tensor=True)
    embeddings_red = modelo.encode(palabras_red, convert_to_tensor=True)

    similitudes = util.pytorch_cos_sim(embedding_concepto, embeddings_red)[0]
    indices_top = similitudes.argsort(descending=True)[:top_n].tolist()
    relacionados = [palabras_red[i] for i in indices_top if palabras_red[i] != nuevo_concepto]

    return relacionados
    

# üîπ Detectar nuevas dualidades autom√°ticamente en la red
def detectar_nuevas_dualidades(G, max_nuevas=10, umbral_similitud=0.85):
    print("üîÑ Detectando nuevas dualidades optimizadas...")

    nuevas_dualidades = {}
    nodos_lista = list(G.nodes())[-max_nuevas:]  # Solo analiza los √∫ltimos nodos agregados

    for nodo in nodos_lista:
        similitudes_nodo = detectar_dualidad_embeddings(nodo, G)  # Obtener conceptos similares

        for otro in similitudes_nodo:
            if otro in G.nodes() and nodo != otro and not G.has_edge(nodo, otro):
                similitud_n2 = detectar_dualidad_embeddings(otro, G)

                # Se consideran dualidades si ambos se tienen alta similitud
                if nodo in similitud_n2 and otro in similitudes_nodo:
                    nuevas_dualidades[nodo] = otro

    # Agregar nuevas dualidades a la red
    for nodo, dual in nuevas_dualidades.items():
        if nodo not in dualidades_base and dual not in dualidades_base:
            dualidades_base[nodo] = dual
            dualidades_base[dual] = nodo
            conectar_dualidad_con_equilibrio(nodo, dual, G)


    print(f"‚úÖ Se detectaron {len(nuevas_dualidades)} nuevas dualidades en la red.")
#    print(f"‚úÖ PAUSA 20s")
#    time.sleep(20)
    return G

def detectar_dualidad(concepto, G, concepto_base=None):
    """ Detecta si existe una dualidad sem√°ntica en la red. """
    # üîπ Buscar dualidades predefinidas primero
    dualidades_predefinidas = {
        "luz": "oscuridad", "positivo": "negativo", "vida": "muerte", "izquierda": "derecha",
        "arriba": "abajo", "orden": "caos"
    }

    if concepto in dualidades_predefinidas:
        dualidad = dualidades_predefinidas[concepto]
        if not G.has_edge(concepto, dualidad):  # Solo conectar si no est√° ya conectado
            print(f"üîÑ Conectando dualidad predefinida: {concepto} ‚Üî {dualidad}")
            conectar_dualidad_con_equilibrio(concepto, dualidad, G)
        return dualidad
    
    # üîπ Buscar en dualidades de WordNet
    dualidades_wordnet = detectar_dualidad_wordnet(concepto)
    if dualidades_wordnet:
        for dualidad in dualidades_wordnet:
            if dualidad in G.nodes() and not G.has_edge(concepto, dualidad):  # Verificar si no existe conexi√≥n
                print(f"üåø Dualidad detectada v√≠a WordNet: {concepto} ‚Üî {dualidad}")
                conectar_dualidad_con_equilibrio(concepto, dualidad, G)
                return dualidad  # Retorna la primera dualidad v√°lida encontrada
    
    # üîπ Detectar dualidad usando embeddings
    max_similitud = 0
    mejor_dualidad = None
    emb_concepto = modelo_embeddings.encode(concepto, convert_to_tensor=True)
    for nodo in G.nodes():
        if nodo == concepto:
            continue
        emb_nodo = modelo_embeddings.encode(nodo, convert_to_tensor=True)
        similitud = util.pytorch_cos_sim(emb_concepto, emb_nodo).item()
        if similitud > max_similitud and similitud >= 0.85:
            max_similitud = similitud
            mejor_dualidad = nodo

    if mejor_dualidad:
        print(f"üîÑ Detectada posible dualidad con embeddings: {concepto} ‚Üî {mejor_dualidad} (Similitud: {max_similitud:.2f})")
        if not G.has_edge(concepto, mejor_dualidad):  # Solo conectar si no existe la conexi√≥n
            conectar_dualidad_con_equilibrio(concepto, mejor_dualidad, G)
        return mejor_dualidad

    return None

def evaluar_expansion(G):
    """ Eval√∫a si una expansi√≥n fue √∫til y ajusta criterios """
    historial = cargar_historial()

    for nodo in G.nodes():
        conexiones = list(G.neighbors(nodo))
        
        if nodo not in historial:
            historial[nodo] = {"conexiones_previas": 0, "exito": 0}
        
        conexiones_previas = historial[nodo]["conexiones_previas"]
        nuevas_conexiones = len(conexiones) - conexiones_previas
        
        # Si la expansi√≥n trajo nuevas conexiones, marcar como exitosa
        if nuevas_conexiones > 0:
            historial[nodo]["exito"] += 1
        
        historial[nodo]["conexiones_previas"] = len(conexiones)

    guardar_historial(historial)
    print("üìä Evaluaci√≥n de expansiones completada.")

def detectar_nodo_superior(concepto, dualidad, G, top_n=3):
    """ Busca un nodo superior din√°mico basado en embeddings. """
    palabras_red = list(G.nodes())
    embedding_concepto = modelo_embeddings.encode(concepto, convert_to_tensor=True)
    embedding_dualidad = modelo_embeddings.encode(dualidad, convert_to_tensor=True)
    embeddings_red = modelo_embeddings.encode(palabras_red, convert_to_tensor=True)

    similitudes_concepto = util.pytorch_cos_sim(embedding_concepto, embeddings_red)[0]
    similitudes_dualidad = util.pytorch_cos_sim(embedding_dualidad, embeddings_red)[0]

    # Promediamos las similitudes con ambos conceptos
    similitudes_totales = (similitudes_concepto + similitudes_dualidad) / 2
    indices_top = similitudes_totales.argsort(descending=True)[:top_n].tolist()

    posibles_superiores = [palabras_red[i] for i in indices_top if palabras_red[i] not in [concepto, dualidad]]

    return posibles_superiores
        

    
# üîπ Ajustar pesos en conexiones de la red fractal
def ajustar_pesos_conexiones(G):
    """
    Modifica los pesos de las conexiones en funci√≥n de su relaci√≥n con dualidades
    y combinaciones de t√©rminos en la red. Se asegura de que los pesos no crezcan descontroladamente.
    """
    max_peso = 5.0  # üîπ L√≠mite superior para evitar l√≠neas excesivamente gruesas
    min_peso = 0.5  # üîπ L√≠mite inferior para que las conexiones no desaparezcan

    for nodo1, nodo2 in G.edges():
        peso_actual = G.edges[nodo1, nodo2].get('weight', 1.0)

        # üîπ Mantener pesos dentro de un rango controlado
        if nodo1 in dualidades_base and dualidades_base[nodo1] == nodo2:
            peso_nuevo = max(2.0, min(peso_actual * 1.1, max_peso))  # Incrementa pero no sobrepasa 5.0
            G.edges[nodo1, nodo2]['weight'] = peso_nuevo
            G.edges[nodo2, nodo1]['weight'] = peso_nuevo

        # üîπ Reducir peso si es demasiado d√©bil
        elif peso_actual < 1.2:
            peso_nuevo = max(min_peso, peso_actual * 0.8)  # Nunca por debajo de 0.5
            G.edges[nodo1, nodo2]['weight'] = peso_nuevo

        # üîπ Aumentar peso si la conexi√≥n aparece muchas veces
        elif G.degree(nodo1) > 3 and G.degree(nodo2) > 3:
            peso_nuevo = min(peso_actual * 1.05, max_peso)  # Incremento menor para evitar sobrecarga
            G.edges[nodo1, nodo2]['weight'] = peso_nuevo

    print("‚úÖ Pesos de conexiones ajustados y normalizados en la red.")
    return G

# üîπ Reorganizar la red eliminando nodos sueltos y corrigiendo conexiones incorrectas
def reorganizar_red(G, max_espera=5):
    """
    Reorganiza la red eliminando nodos sueltos solo despu√©s de un n√∫mero de iteraciones.
    Tambi√©n corrige conexiones err√≥neas basadas en dualidades.
    Ahora los nodos en espera se guardan en un archivo para evitar perder informaci√≥n si el programa se reinicia.
    """

    global espera_nodos
    nodos_actuales = set(G.nodes())

    # Actualizar lista de espera: eliminar nodos que ya tienen conexi√≥n
    for nodo in list(espera_nodos.keys()):
        if nodo not in nodos_actuales or G.degree(nodo) > 0:
            del espera_nodos[nodo]

    # Revisar nodos sueltos
    for nodo in nodos_actuales:
        if G.degree(nodo) == 0 and nodo != NODO_CENTRAL:
            if nodo not in espera_nodos:
                espera_nodos[nodo] = 0  # Primera vez en espera
                #G.add_edge(nodo, NODO_CENTRAL, weight=0.5)  # Conexi√≥n temporal

            elif espera_nodos[nodo] >= max_espera:
                print(f"üóë Eliminando nodo suelto por falta de conexiones: {nodo}")
                G.remove_node(nodo)
                del espera_nodos[nodo]
            else:
                espera_nodos[nodo] += 1  # Aumentar contador de espera

    # Guardar lista de espera actualizada
    guardar_espera_nodos(espera_nodos)

    # Corregir conexiones incorrectas basadas en dualidades
    for nodo in list(G.nodes()):
        for otro in list(G.nodes()):
            if nodo != otro and nodo in dualidades_base and dualidades_base[nodo] == otro:
                if not G.has_edge(nodo, otro):
                    G.add_edge(nodo, otro, weight=2.0)

    print("‚úÖ Red reorganizada: nodos sueltos en espera, conexiones corregidas.")
    return G
    
def guardar_estado_parcial(G, espera_nodos):
    # Guarda la red y los nodos pendientes en un archivo temporal
    with open('estado_parcial.json', 'w') as f:
        json.dump({
            'nodos': list(G.nodes()),
            'edges': list(G.edges()),
            'espera_nodos': espera_nodos
        }, f)
    print("‚ö° Estado parcial guardado correctamente.")


# üîπ Modificar la funci√≥n agregar_nuevo_nodo para evitar redundancias
def agregar_nuevo_nodo(G, diccionario, conceptos):
    """ Agrega un nuevo nodo a la red fractal y detecta dualidades con equilibrio. """
    conceptos = [normalizar_termino(c) for c in conceptos]
    conceptos = [corregir_termino(c, diccionario) for c in conceptos]  # Correcci√≥n de t√©rminos
    
    nuevos_conceptos = []
    nodos_existentes = set(G.nodes())

    for concepto in conceptos:
        concepto = concepto.replace("_", " ")  # üîπ Asegurar formato correcto
        raiz = obtener_raiz(concepto)

        if any(raiz in nodo for nodo in nodos_existentes):
            print(f"‚ö†Ô∏è Se ha detectado redundancia con '{concepto}'. No se a√±adir√° a la red.")
            continue

        if concepto in nodos_existentes:
            print(f"‚ö†Ô∏è El concepto '{concepto}' ya est√° en la red. No se realizar√°n cambios.")
            continue

        # üîπ Agregar nodo a la red
        G.add_node(concepto)
        nuevos_conceptos.append(concepto)

        # üîπ Detectar dualidad y conectar con equilibrio si es necesario
        dualidad_opuesta = detectar_dualidad(concepto, G, concepto)

        if dualidad_opuesta:
            dualidad_opuesta = dualidad_opuesta.replace("_", " ")
            if dualidad_opuesta in G.nodes():
                conectar_dualidad_con_equilibrio(concepto, dualidad_opuesta, G)
                print(f"‚úÖ Se ha conectado la dualidad: {concepto} ‚Üî {dualidad_opuesta}")

        # üîπ Agregar al diccionario
        diccionario.setdefault(concepto, [])
        if dualidad_opuesta:
            diccionario[concepto].append(dualidad_opuesta)

    # üîπ Optimizar la red solo si se a√±adieron nuevos conceptos
    if nuevos_conceptos:
        print("üîÑ Procesando ajustes globales de la red...")
        G = ajustar_pesos_conexiones(G)
        G = reorganizar_red(G)
        G = detectar_nuevas_dualidades(G)
        print(f"‚úÖ {len(nuevos_conceptos)} nuevos conceptos a√±adidos.")
    else:
        print("‚úÖ No se realizaron cambios en la red.")

    return G

def expansion_dinamica(G, diccionario):
    """ Detecta nodos aislados y los expande din√°micamente """
    nodos_a_expandir = [nodo for nodo in G.nodes() if G.degree(nodo) < 2 and nodo.lower() != NODO_CENTRAL.lower()]

    for nodo in nodos_a_expandir:
        nodo = nodo.lower()  # üîπ Forzar a min√∫sculas

        print(f"üöÄ Expansi√≥n autom√°tica para: {nodo}")
        consultar_wikipedia(nodo, G, diccionario)
        nuevos_conceptos = consultar_chatgpt(nodo, diccionario)

        if nuevos_conceptos:
            G = agregar_nuevo_nodo(G, diccionario, nuevos_conceptos)
        
        expandir_concepto_embedding(nodo, G, diccionario)

    guardar_red(G)

# üîπ Expandir la red fractal con embeddings
def expandir_concepto_embedding(concepto, G, diccionario, top_n=5):
    palabras_red = list(G.nodes())
    if concepto not in palabras_red:
        G.add_node(concepto)

    embedding_concepto = modelo.encode(concepto, convert_to_tensor=True)
    embeddings_red = modelo.encode(palabras_red, convert_to_tensor=True)

    similitudes = util.pytorch_cos_sim(embedding_concepto, embeddings_red)[0]
    indices_top = similitudes.argsort(descending=True)[:top_n].tolist()
    relacionados = [palabras_red[i] for i in indices_top if palabras_red[i] != concepto]

    for i, termino in enumerate(relacionados):
        # peso = np.tanh(similitudes[indices_top[i]].item())  # Usa tanh para normalizar
        peso = np.exp(similitudes[indices_top[i]].item())

        G.add_edge(concepto, termino, weight=peso)

    diccionario[concepto] = relacionados
    with open("diccionario.json", "w", encoding="utf-8") as f:
        json.dump(diccionario, f, ensure_ascii=False, indent=4)

    # Ajustar pesos de conexiones despu√©s de la expansi√≥n
    G = ajustar_pesos_conexiones(G)
    G = reorganizar_red(G)
    G = detectar_nuevas_dualidades(G)

    guardar_red(G)
    return relacionados

# üîπ Visualizar la red fractal con mejor distribuci√≥n
def visualizar_red(G):
    net = Network(height="900px", width="100%", directed=True, notebook=False)
    print("üìä Cargando nodos para visualizaci√≥n...")
    
    # üîπ Usar layout de resorte (spring_layout) para una distribuci√≥n m√°s natural
    posiciones = nx.spring_layout(G, k=0.5, iterations=50)  # k controla la dispersi√≥n

    for nodo, coords in posiciones.items():
        x, y = coords[0] * 2000, coords[1] * 2000  # Ajustar escala de distribuci√≥n
        color = (
            "green" if nodo == NODO_CENTRAL else
            "orange" if nodo in dualidades_base else
            "blue"
        )
        net.add_node(nodo, label=nodo, color=color, size=20, x=x, y=y, physics=True)

    # üîπ Configurar f√≠sicas en PyVis para evitar colapso de nodos
#    net.force_atlas_2based(gravity=-50, central_gravity=0.005, spring_length=250, spring_strength=0.1)
    #net.force_atlas_2based(gravity=-100, central_gravity=0.005, spring_length=500, spring_strength=0.1)
    net.set_options("""
        var options = {
            "physics": {
                "barnesHut": {
                    "gravitationalConstant": -3000,
                    "centralGravity": 0.3,
                    "springLength": 95,
                    "springConstant": 0.04
                }
            }
        }
    """)

    for edge in G.edges():
        net.add_edge(edge[0], edge[1], color="gray", width=G.edges[edge].get('weight', 1.5))

    print(f"‚úÖ Nodos en la visualizaci√≥n: {len(G.nodes())}")
    print(f"‚úÖ Conexiones en la visualizaci√≥n: {len(G.edges())}")


    net.write_html("hipercubo_fractal.html")
    print("‚úÖ Hipercubo fractal guardado como 'hipercubo_fractal.html'.")

# üîπ Modificar la funci√≥n expansi√≥n autom√°tica para incluir expansi√≥n prioritaria
def expansion_automatica(G, diccionario, expansion_activa, intervalo=5):
    """ Expande la red autom√°ticamente cada X segundos si est√° activa """
    while expansion_activa:
        print("üîÑ Iniciando expansi√≥n autom√°tica con prioridad...")
        expansion_prioritaria(G, diccionario)  # Integrando la expansi√≥n prioritaria
        
        nodos_a_expandir = [nodo for nodo in G.nodes() if G.degree(nodo) < 3 and nodo.lower() != NODO_CENTRAL.lower()]

        for nodo in nodos_a_expandir:
            if not expansion_activa:
                print("‚èπÔ∏è Expansi√≥n autom√°tica detenida.")
                return
                
            nodo = nodo.lower()

            print(f"üîç Expandiendo nodo aislado: {nodo}")
            resultado_wikipedia = consultar_wikipedia(nodo, G, diccionario)
            nuevos_conceptos = consultar_chatgpt(nodo, diccionario)

            if nuevos_conceptos:
                G = agregar_nuevo_nodo(G, diccionario, nuevos_conceptos)
                registrar_expansion(nodo, nuevos_conceptos, "GPT-4")
                guardar_diccionario(diccionario)

            expandir_concepto_embedding(nodo, G, diccionario)
            registrar_expansion(nodo, [], "Embeddings")
            guardar_diccionario(diccionario)

        guardar_red(G)
        reorganizar_red(G)
        evaluar_expansion(G)
        guardar_historial(cargar_historial())

        print("‚úÖ Expansi√≥n autom√°tica completada. Esperando nuevo ciclo...")
        visualizar_red(G)
        print("‚è≥ Esperando antes del pr√≥ximo ciclo...")
        generar_reportes()
        time.sleep(intervalo)

if __name__ == "__main__":
    # Cargar el grafo desde "grafo_consciencia.json"
    G_archivo = cargar_grafo()

    # Cargar la red desde "red_fractal.json"
    G_red, diccionario = cargar_red()

    # Fusionar ambos grafos (si es necesario)
    G = nx.compose(G_archivo, G_red)  # Une los dos grafos sin perder nodos ni conexiones


    print("üîÑ Reorganizando la red para conectar nodos en espera...")
    G = reorganizar_red(G)

    print(f"üìä Nodos cargados: {len(G.nodes())}")
    print(f"üîó Conexiones cargadas: {len(G.edges())}")
    print("üßê Nodos sueltos en espera:", [nodo for nodo in G.nodes() if G.degree(nodo) == 0])

    if NODO_CENTRAL and NODO_CENTRAL in G:
        # Contar cu√°ntos nodos est√°n directamente conectados al nodo central
        conexiones_centrales = Counter(G.neighbors(NODO_CENTRAL))
        umbral_conexiones = 2  # Ajusta este n√∫mero seg√∫n lo que desees mostrar

        print(f"üîç Nodos con muchas conexiones directas a '{NODO_CENTRAL}':")
        for nodo in conexiones_centrales:
            if G.degree(nodo) > umbral_conexiones:
                print(f"{nodo}: {G.degree(nodo)} conexiones")
        print(f"üîó Conexiones del nodo central '{NODO_CENTRAL}':")
        for vecino in G.neighbors(NODO_CENTRAL):
            print(f"{vecino}: {G.degree(vecino)} conexiones")


    try:
        while True:
            entrada = input("\nü§î Opciones: [salir] [ver red] [a√±adir] [expandir] [historial] [auto]: ").strip().lower()

            if entrada == "salir":
                print("üëã Saliendo... Guardando cambios en la red.")
                guardar_red(G)
                break  # üîπ Evita usar sys.exit(0), permitiendo un cierre m√°s natural

            elif entrada == "ver red":
                visualizar_red(G)
                print("üåü Conceptos en la red:", {len(G.nodes())})
#                for nodo in G.nodes():
#                    print(f"- {nodo}")  # üîπ Se restaur√≥ la lista de conceptos en la red

                # Guardar gr√°fico en archivo en lugar de mostrarlo en pantalla
                plt.figure(figsize=(10, 5))
                plt.hist([G.degree(nodo) for nodo in G.nodes()], bins=10, color="blue", alpha=0.7)
                plt.xlabel("N√∫mero de conexiones por nodo")
                plt.ylabel("Cantidad de nodos")
                plt.title("Distribuci√≥n de Conexiones en la Red Fractal")
                plt.grid()
                plt.savefig("grafico_red.png")
                print("üé® Gr√°fico guardado como 'grafico_red.png'. √Åbrelo manualmente.")

            elif entrada == "a√±adir":
                conceptos = input("‚ûû Introduce conceptos separados por espacio. Si el concepto tiene espacios usa \"_\" para separar palabras: ").strip().split()
                G = agregar_nuevo_nodo(G, diccionario, conceptos)
                guardar_red(G)

            elif entrada == "expandir":
                concepto = input("‚ûû Concepto a expandir: ").strip()
                print("üìö Expandiendo desde Wikipedia y GPT...")
                resultado_wikipedia = consultar_wikipedia(concepto, G, diccionario)
                nuevos_conceptos = consultar_chatgpt(concepto, diccionario)
                if nuevos_conceptos:
                    G = agregar_nuevo_nodo(G, diccionario, nuevos_conceptos)
                
                # üîπ Se restaur√≥ la verificaci√≥n antes de expandir con embeddings
                if concepto in G.nodes():
                    print("üîÑ Expandiendo con embeddings...")
                    expandir_concepto_embedding(concepto, G, diccionario)
                else:
                    print("‚ö†Ô∏è El concepto no est√° en la red. No se expandir√° con embeddings.")

                guardar_red(G)

            elif entrada == "historial":
                ver_registro()
                
            elif entrada == "auto":
                print("‚ö° Iniciando expansi√≥n autom√°tica y din√°mica... (Presiona Ctrl+C para detener)")
                expansion_activa = True

                try:
                    while expansion_activa:
                        expansion_automatica(G, diccionario, expansion_activa)
                        expansion_dinamica(G, diccionario)  # üîπ Se a√±ade la expansi√≥n din√°mica aqu√≠                     

                        for _ in range(10):  # Espera en intervalos m√°s cortos para permitir interrupci√≥n r√°pida
                            if not expansion_activa:
                                break
                            time.sleep(1)  # Espera en intervalos de 1 segundo para mejorar respuesta a Ctrl+C
                except KeyboardInterrupt:
                    print("\n‚èπ Expansi√≥n detenida por el usuario.")
                    expansion_activa = False
                    guardar_red(G)

            else:
                print(f"‚ö†Ô∏è Entrada err√≥nea '{entrada}'.")
    
    except KeyboardInterrupt:
        print("\nüëã Interrupci√≥n detectada. Guardando y cerrando de manera segura...")
        expansion_activa = False
        guardar_red(G)

